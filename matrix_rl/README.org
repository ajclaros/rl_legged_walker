#+title: Matrix Based RL

* Parametrization
Given a network of $M$ nodes and a maximum of $N$ parameters per node, we can create a $M\times N$ matrix to map all the parameters of a system. For example in the case of a 3 node ctrnn we can create:
|           | $N_0$ | $N_1$   | $N_2$ |
| w_{0j}    |       |         |       |
| w_{1j}    |       |         |       |
| w_{2j}    |       |         |       |
| b_{j}     |       |         |       |
| \tau_{j}  |       |         |       |

This enables the capacity for the learning rule to be applied generally to a heterogeneous system where all parameters (initial and max flux amplitudes, period ranges, parameter bounds) can be specifically tuned for each parameter. For this specific implementation, $\tau$'s are not learning parameters, therefore their associated positions associated for init_flux, max_flux are 0.

In the case of a heterogeneous system (systems that have different intrinsic properties such as neurons that learn at different rates, a system containing neurons and muscles,  or heterogeneous servo motors physical robotics) one can specify each parameter to have their own learning and convergence rates. Because this specific system is homogeneous learning and convergence rates are just floats.

- The script to run is single_trial.py
- All functions of learning rule are contained within learning_rule.py.

- RLCTRNN has two versions for updating. the functions denoted with a "2" contain manually implemented ring buffers whereas the original updating functions use np.roll.
- the manual implementation of the ring buffer decreases runtime by ~1.8 as np.roll creates a new array each time.

- The difference between CTRNN and RL_CTRNN is:
  + Step function uses the fluctuating weights
  + Step function calculates the next moment of the fluctuating weights
  + RL_CTRNN implements the reward and performance functions.







* Running run_trials.py
** Generating genomes
- If this is the first time the script is run, genomes will be generated. Parallel evolutionary runs will execute depending on the /num_processes/ variable.

- If the specified agent parameters do not exist within the /evolved/ folder, single_trial.py will create the folder and run an evolutionary algorithm to generate genomes
- If it does exist, the function checks if there is a minimum amount of genomes within a fitness range. If not, the evolutionary algorithm will run and save genomes within the specified range

** Running trials
- These genomes are starting points for learning algorithm to use
- Current state of the parameters will generally show learning for generator:RPG, size:3, neuron 0 driving leg movement
- Harder tasks are less stable at higher performance values (~0.5)

*** Plotting variables:
Variables of an agent can be tracked using /plot_vars/. Use the parameter "record_every" to dictate recording data every nth step. There are three tags associated with the agent:
- "track": Agent window variables (window_a, window_b, distance). Note that when recording performance the agent is recording performance as perceived by the agent, which is offset by a delay.
- "avg": Take the window's average and track it throughout the trial.
- "mat": tracks the agents matrix variables. Only tracks the variable associated in location [0,0]
- TODO: "no_delay" is buggy. Should show performance alongside the first averaging window irrespective of delay
