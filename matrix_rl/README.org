#+title: Matrix Based RL

* Parametrization
Given a network of $M$ nodes and a maximum of $N$ parameters per node, we can create a $M\times N$ matrix to map all the parameters of a system. For example in the case of a 3 node ctrnn we can create:
|           | $N_0$ | $N_1$   | $N_2$ |
| w_{0j}    |       |         |       |
| w_{1j}    |       |         |       |
| w_{2j}    |       |         |       |
| b_{j}     |       |         |       |
| \tau_{j}  |       |         |       |

This enables the capacity for the learning rule to be applied generally to a heterogeneous system where all parameters (initial and max flux amplitudes, period ranges, parameter bounds) can be specifically tuned for each parameter. For this specific implementation, $\tau$'s are not learning parameters, therefore their associated positions associated for init_flux, max_flux are 0.

In the case of a heterogeneous system (systems that have different intrinsic properties such as neurons that learn at different rates, a system containing neurons and muscles,  or heterogeneous servo motors physical robotics) one can specify each parameter to have their own learning and convergence rates. Because this specific system is homogeneous learning and convergence rates are just floats.

- The script to run is single_trial.py
- All functions of learning rule are contained within learning_rule.py.

- The difference between CTRNN and RL_CTRNN is:
  + Step function uses the fluctuating weights
  + Step function calculates the next moment of the fluctuating weights
  + RL_CTRNN implements the reward and performance functions.




* Running run_trials.py
** Generating genomes
- If this is the first time the script is run, genomes will be generated. Parallel evolutionary runs will execute depending on the /num_processes/ variable.

- If the specified agent parameters do not exist within the /evolved/ folder, single_trial.py will create the folder and run an evolutionary algorithm to generate genomes
- If it does exist, the function checks if there is a minimum amount of genomes within a fitness range. If not, the evolutionary algorithm will run and save genomes within the specified range

** Running trials
- These genomes are starting points for learning algorithm to use
- Current state of the parameters will generally show learning for generator:RPG, size:3, neuron 0 driving leg movement

After trial will plot:
1) Real time performance
2) Performance as seen by the agent
3) Mean of both averaging windows (window_b refers to the current performance and window_a refers to past performance)
4) Difference of the two windows which will pass in to the agent as a reward modulatory signal
4) Fluctuation amplitude
